{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import fd_imputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up all paths and labels needed in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'MLFD_fd_detection/backend/WEB-INF/classes/inputData/adult.csv'\n",
    "SPLITS_PATH = 'MLFD_fd_detection/data/'\n",
    "METANOME_DATA_PATH = 'MLFD_fd_detection/backend/WEB-INF/classes/inputData/'\n",
    "FD_PATH = 'MLFD_fd_detection/results/HyFD-1.2-SNAPSHOT.jar2019-05-07T082200_fds'\n",
    "DATA_TITLE = 'adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(SPLITS_PATH+'test/'+DATA_TITLE+'_test.csv', header=None)\n",
    "df_test = pd.read_csv(SPLITS_PATH+'train/'+DATA_TITLE+'_train.csv', header=None)\n",
    "fds = fd_imputer.read_fds(FD_PATH)\n",
    "impute_column = str(9)\n",
    "df_test = df_test.replace('noValueSetHere123156456', np.nan)\n",
    "df_train = df_train.replace('noValueSetHere123156456', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Problem bzgl. eines geeigneten Fehlermaßes zeigt sich zeigt sich in den folgenden beiden Zellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-04 16:12:13,919 [INFO]  \n",
      "========== start: fit model\n",
      "2019-06-04 16:12:13,920 [WARNING]  Already bound, ignoring bind()\n",
      "2019-06-04 16:12:14,149 [INFO]  Epoch[0] Batch [0-184]\tSpeed: 13148.13 samples/sec\tcross-entropy=0.478446\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:14,356 [INFO]  Epoch[0] Train-cross-entropy=0.243092\n",
      "2019-06-04 16:12:14,357 [INFO]  Epoch[0] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:14,358 [INFO]  Epoch[0] Time cost=0.436\n",
      "2019-06-04 16:12:14,363 [INFO]  Saved checkpoint to \"imputer_model/model-0000.params\"\n",
      "2019-06-04 16:12:14,394 [INFO]  Epoch[0] Validation-cross-entropy=0.002516\n",
      "2019-06-04 16:12:14,395 [INFO]  Epoch[0] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:14,622 [INFO]  Epoch[1] Batch [0-184]\tSpeed: 13176.01 samples/sec\tcross-entropy=0.002311\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:14,839 [INFO]  Epoch[1] Train-cross-entropy=0.001421\n",
      "2019-06-04 16:12:14,840 [INFO]  Epoch[1] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:14,842 [INFO]  Epoch[1] Time cost=0.446\n",
      "2019-06-04 16:12:14,848 [INFO]  Saved checkpoint to \"imputer_model/model-0001.params\"\n",
      "2019-06-04 16:12:14,883 [INFO]  Epoch[1] Validation-cross-entropy=0.000306\n",
      "2019-06-04 16:12:14,885 [INFO]  Epoch[1] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,180 [INFO]  Epoch[2] Batch [0-184]\tSpeed: 10098.05 samples/sec\tcross-entropy=0.000419\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,394 [INFO]  Epoch[2] Train-cross-entropy=0.000380\n",
      "2019-06-04 16:12:15,395 [INFO]  Epoch[2] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,401 [INFO]  Epoch[2] Time cost=0.515\n",
      "2019-06-04 16:12:15,406 [INFO]  Saved checkpoint to \"imputer_model/model-0002.params\"\n",
      "2019-06-04 16:12:15,447 [INFO]  Epoch[2] Validation-cross-entropy=0.000582\n",
      "2019-06-04 16:12:15,453 [INFO]  Epoch[2] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,713 [INFO]  Epoch[3] Batch [0-184]\tSpeed: 11582.08 samples/sec\tcross-entropy=0.000354\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,938 [INFO]  Epoch[3] Train-cross-entropy=0.000347\n",
      "2019-06-04 16:12:15,939 [INFO]  Epoch[3] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,939 [INFO]  Epoch[3] Time cost=0.483\n",
      "2019-06-04 16:12:15,943 [INFO]  Saved checkpoint to \"imputer_model/model-0003.params\"\n",
      "2019-06-04 16:12:15,978 [INFO]  Epoch[3] Validation-cross-entropy=0.000743\n",
      "2019-06-04 16:12:15,982 [INFO]  Epoch[3] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,234 [INFO]  Epoch[4] Batch [0-184]\tSpeed: 11895.57 samples/sec\tcross-entropy=0.000722\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,447 [INFO]  Epoch[4] Train-cross-entropy=0.001093\n",
      "2019-06-04 16:12:16,448 [INFO]  Epoch[4] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,449 [INFO]  Epoch[4] Time cost=0.464\n",
      "2019-06-04 16:12:16,453 [INFO]  Saved checkpoint to \"imputer_model/model-0004.params\"\n",
      "2019-06-04 16:12:16,490 [INFO]  Epoch[4] Validation-cross-entropy=0.008812\n",
      "2019-06-04 16:12:16,492 [INFO]  Epoch[4] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,730 [INFO]  Epoch[5] Batch [0-184]\tSpeed: 12575.29 samples/sec\tcross-entropy=0.032752\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,928 [INFO]  Epoch[5] Train-cross-entropy=0.016692\n",
      "2019-06-04 16:12:16,931 [INFO]  Epoch[5] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,931 [INFO]  Epoch[5] Time cost=0.439\n",
      "2019-06-04 16:12:16,937 [INFO]  Saved checkpoint to \"imputer_model/model-0005.params\"\n",
      "2019-06-04 16:12:16,995 [INFO]  Epoch[5] Validation-cross-entropy=0.000132\n",
      "2019-06-04 16:12:16,997 [INFO]  Epoch[5] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:17,276 [INFO]  Epoch[6] Batch [0-184]\tSpeed: 11230.64 samples/sec\tcross-entropy=0.000372\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:17,523 [INFO]  Epoch[6] Train-cross-entropy=0.000301\n",
      "2019-06-04 16:12:17,525 [INFO]  Epoch[6] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:17,527 [INFO]  Epoch[6] Time cost=0.529\n",
      "2019-06-04 16:12:17,532 [INFO]  Saved checkpoint to \"imputer_model/model-0006.params\"\n",
      "2019-06-04 16:12:17,584 [INFO]  Epoch[6] Validation-cross-entropy=0.000671\n",
      "2019-06-04 16:12:17,585 [INFO]  Epoch[6] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:17,840 [INFO]  Epoch[7] Batch [0-184]\tSpeed: 11901.12 samples/sec\tcross-entropy=0.025736\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,065 [INFO]  Epoch[7] Train-cross-entropy=0.014327\n",
      "2019-06-04 16:12:18,066 [INFO]  Epoch[7] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,067 [INFO]  Epoch[7] Time cost=0.477\n",
      "2019-06-04 16:12:18,071 [INFO]  Saved checkpoint to \"imputer_model/model-0007.params\"\n",
      "2019-06-04 16:12:18,106 [INFO]  Epoch[7] Validation-cross-entropy=0.000977\n",
      "2019-06-04 16:12:18,108 [INFO]  Epoch[7] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,396 [INFO]  Epoch[8] Batch [0-184]\tSpeed: 10322.58 samples/sec\tcross-entropy=0.003473\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,601 [INFO]  Epoch[8] Train-cross-entropy=0.002078\n",
      "2019-06-04 16:12:18,601 [INFO]  Epoch[8] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,602 [INFO]  Epoch[8] Time cost=0.494\n",
      "2019-06-04 16:12:18,609 [INFO]  Saved checkpoint to \"imputer_model/model-0008.params\"\n",
      "2019-06-04 16:12:18,658 [INFO]  Epoch[8] Validation-cross-entropy=0.000366\n",
      "2019-06-04 16:12:18,660 [INFO]  Epoch[8] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,932 [INFO]  Epoch[9] Batch [0-184]\tSpeed: 10990.31 samples/sec\tcross-entropy=0.006925\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:19,192 [INFO]  Epoch[9] Train-cross-entropy=0.012340\n",
      "2019-06-04 16:12:19,194 [INFO]  Epoch[9] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:19,196 [INFO]  Epoch[9] Time cost=0.534\n",
      "2019-06-04 16:12:19,205 [INFO]  Saved checkpoint to \"imputer_model/model-0009.params\"\n",
      "2019-06-04 16:12:19,244 [INFO]  Epoch[9] Validation-cross-entropy=0.002657\n",
      "2019-06-04 16:12:19,246 [INFO]  Epoch[9] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:19,547 [INFO]  Epoch[10] Batch [0-184]\tSpeed: 9965.40 samples/sec\tcross-entropy=0.005685\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:19,790 [INFO]  Epoch[10] Train-cross-entropy=0.003032\n",
      "2019-06-04 16:12:19,792 [INFO]  Epoch[10] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:19,793 [INFO]  Epoch[10] Time cost=0.545\n",
      "2019-06-04 16:12:19,800 [INFO]  Saved checkpoint to \"imputer_model/model-0010.params\"\n",
      "2019-06-04 16:12:19,824 [INFO]  No improvement detected for 5 epochs compared to 0.00013178860234159113 last error obtained: 0.0002905159365959329, stopping here\n",
      "2019-06-04 16:12:19,826 [INFO]  \n",
      "========== done (5.906533241271973 s) fit model\n"
     ]
    }
   ],
   "source": [
    "# Waehle eine beliebige FD, auf der datawig regressiert\n",
    "rhs = list(fds.keys())[0]\n",
    "lhs = fds[rhs][0]\n",
    "relevant_cols = lhs + [rhs]\n",
    "\n",
    "# ml_imputer() ist ein wrapper fuer datawig.SimpleImputer()\n",
    "df_imputed = fd_imputer.ml_imputer(df_train.iloc[:,relevant_cols], df_test.iloc[:,relevant_cols], rhs)\n",
    "\n",
    "y_pred = df_imputed.loc[:, str(rhs)+'_imputed']\n",
    "y_true = df_imputed.loc[:, str(rhs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-5f584f3c513d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m {\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m }\n",
      "\u001b[0;32m~/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1567\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1570\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                          str(average_options))\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "{\n",
    "'precision': metrics.precision_score(y_true, y_pred, average='weighted'),\n",
    "'recall': metrics.recall_score(y_true, y_pred, average='weighted'),\n",
    "'f1': metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Problem ließe sich umgehen, indem Werte aus y_pred gerundet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/philipp/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0011578136578136579"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_true, y_pred.apply(lambda x: round(x)), average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aber das ist glaube ich nicht wirklich sinnvoll - bei Regression geht es ja nicht darum, einen exakten Wert auszugeben, sondern vielmehr darum, den mittleren Fehler der einzelnen Vorhersagen zu minimieren.\n",
    "So würde ein gutes Modell, dessen Vorhersagen aber immer um ±0.5 neben dem korrekten Wert liegen, einen f1-Score von 0 haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ könnte man relative oder absolute Fehler berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0.0663%\n"
     ]
    }
   ],
   "source": [
    "average_rel_error = abs((y_true.mean() - y_pred.mean()) / y_true.mean())\n",
    "print(\"{:10.4f}\".format(100*average_rel_error)+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
