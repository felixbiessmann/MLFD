{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import fd_imputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up all paths and labels needed in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'MLFD_fd_detection/backend/WEB-INF/classes/inputData/adult.csv'\n",
    "SPLITS_PATH = 'MLFD_fd_detection/data/'\n",
    "METANOME_DATA_PATH = 'MLFD_fd_detection/backend/WEB-INF/classes/inputData/'\n",
    "FD_PATH = 'MLFD_fd_detection/results/HyFD-1.2-SNAPSHOT.jar2019-05-07T082200_fds'\n",
    "DATA_TITLE = 'adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(SPLITS_PATH+'test/'+DATA_TITLE+'_test.csv', header=None)\n",
    "df_test = pd.read_csv(SPLITS_PATH+'train/'+DATA_TITLE+'_train.csv', header=None)\n",
    "fds = fd_imputer.read_fds(FD_PATH)\n",
    "impute_column = str(9)\n",
    "df_test = df_test.replace('noValueSetHere123156456', np.nan)\n",
    "df_train = df_train.replace('noValueSetHere123156456', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Problem bzgl. eines geeigneten Fehlerma√ües zeigt sich zeigt sich in den folgenden beiden Zellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-04 16:12:13,919 [INFO]  \n",
      "========== start: fit model\n",
      "2019-06-04 16:12:13,920 [WARNING]  Already bound, ignoring bind()\n",
      "2019-06-04 16:12:14,149 [INFO]  Epoch[0] Batch [0-184]\tSpeed: 13148.13 samples/sec\tcross-entropy=0.478446\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:14,356 [INFO]  Epoch[0] Train-cross-entropy=0.243092\n",
      "2019-06-04 16:12:14,357 [INFO]  Epoch[0] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:14,358 [INFO]  Epoch[0] Time cost=0.436\n",
      "2019-06-04 16:12:14,363 [INFO]  Saved checkpoint to \"imputer_model/model-0000.params\"\n",
      "2019-06-04 16:12:14,394 [INFO]  Epoch[0] Validation-cross-entropy=0.002516\n",
      "2019-06-04 16:12:14,395 [INFO]  Epoch[0] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:14,622 [INFO]  Epoch[1] Batch [0-184]\tSpeed: 13176.01 samples/sec\tcross-entropy=0.002311\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:14,839 [INFO]  Epoch[1] Train-cross-entropy=0.001421\n",
      "2019-06-04 16:12:14,840 [INFO]  Epoch[1] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:14,842 [INFO]  Epoch[1] Time cost=0.446\n",
      "2019-06-04 16:12:14,848 [INFO]  Saved checkpoint to \"imputer_model/model-0001.params\"\n",
      "2019-06-04 16:12:14,883 [INFO]  Epoch[1] Validation-cross-entropy=0.000306\n",
      "2019-06-04 16:12:14,885 [INFO]  Epoch[1] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,180 [INFO]  Epoch[2] Batch [0-184]\tSpeed: 10098.05 samples/sec\tcross-entropy=0.000419\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,394 [INFO]  Epoch[2] Train-cross-entropy=0.000380\n",
      "2019-06-04 16:12:15,395 [INFO]  Epoch[2] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,401 [INFO]  Epoch[2] Time cost=0.515\n",
      "2019-06-04 16:12:15,406 [INFO]  Saved checkpoint to \"imputer_model/model-0002.params\"\n",
      "2019-06-04 16:12:15,447 [INFO]  Epoch[2] Validation-cross-entropy=0.000582\n",
      "2019-06-04 16:12:15,453 [INFO]  Epoch[2] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,713 [INFO]  Epoch[3] Batch [0-184]\tSpeed: 11582.08 samples/sec\tcross-entropy=0.000354\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,938 [INFO]  Epoch[3] Train-cross-entropy=0.000347\n",
      "2019-06-04 16:12:15,939 [INFO]  Epoch[3] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:15,939 [INFO]  Epoch[3] Time cost=0.483\n",
      "2019-06-04 16:12:15,943 [INFO]  Saved checkpoint to \"imputer_model/model-0003.params\"\n",
      "2019-06-04 16:12:15,978 [INFO]  Epoch[3] Validation-cross-entropy=0.000743\n",
      "2019-06-04 16:12:15,982 [INFO]  Epoch[3] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,234 [INFO]  Epoch[4] Batch [0-184]\tSpeed: 11895.57 samples/sec\tcross-entropy=0.000722\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,447 [INFO]  Epoch[4] Train-cross-entropy=0.001093\n",
      "2019-06-04 16:12:16,448 [INFO]  Epoch[4] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,449 [INFO]  Epoch[4] Time cost=0.464\n",
      "2019-06-04 16:12:16,453 [INFO]  Saved checkpoint to \"imputer_model/model-0004.params\"\n",
      "2019-06-04 16:12:16,490 [INFO]  Epoch[4] Validation-cross-entropy=0.008812\n",
      "2019-06-04 16:12:16,492 [INFO]  Epoch[4] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,730 [INFO]  Epoch[5] Batch [0-184]\tSpeed: 12575.29 samples/sec\tcross-entropy=0.032752\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,928 [INFO]  Epoch[5] Train-cross-entropy=0.016692\n",
      "2019-06-04 16:12:16,931 [INFO]  Epoch[5] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:16,931 [INFO]  Epoch[5] Time cost=0.439\n",
      "2019-06-04 16:12:16,937 [INFO]  Saved checkpoint to \"imputer_model/model-0005.params\"\n",
      "2019-06-04 16:12:16,995 [INFO]  Epoch[5] Validation-cross-entropy=0.000132\n",
      "2019-06-04 16:12:16,997 [INFO]  Epoch[5] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:17,276 [INFO]  Epoch[6] Batch [0-184]\tSpeed: 11230.64 samples/sec\tcross-entropy=0.000372\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:17,523 [INFO]  Epoch[6] Train-cross-entropy=0.000301\n",
      "2019-06-04 16:12:17,525 [INFO]  Epoch[6] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:17,527 [INFO]  Epoch[6] Time cost=0.529\n",
      "2019-06-04 16:12:17,532 [INFO]  Saved checkpoint to \"imputer_model/model-0006.params\"\n",
      "2019-06-04 16:12:17,584 [INFO]  Epoch[6] Validation-cross-entropy=0.000671\n",
      "2019-06-04 16:12:17,585 [INFO]  Epoch[6] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:17,840 [INFO]  Epoch[7] Batch [0-184]\tSpeed: 11901.12 samples/sec\tcross-entropy=0.025736\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,065 [INFO]  Epoch[7] Train-cross-entropy=0.014327\n",
      "2019-06-04 16:12:18,066 [INFO]  Epoch[7] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,067 [INFO]  Epoch[7] Time cost=0.477\n",
      "2019-06-04 16:12:18,071 [INFO]  Saved checkpoint to \"imputer_model/model-0007.params\"\n",
      "2019-06-04 16:12:18,106 [INFO]  Epoch[7] Validation-cross-entropy=0.000977\n",
      "2019-06-04 16:12:18,108 [INFO]  Epoch[7] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,396 [INFO]  Epoch[8] Batch [0-184]\tSpeed: 10322.58 samples/sec\tcross-entropy=0.003473\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,601 [INFO]  Epoch[8] Train-cross-entropy=0.002078\n",
      "2019-06-04 16:12:18,601 [INFO]  Epoch[8] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,602 [INFO]  Epoch[8] Time cost=0.494\n",
      "2019-06-04 16:12:18,609 [INFO]  Saved checkpoint to \"imputer_model/model-0008.params\"\n",
      "2019-06-04 16:12:18,658 [INFO]  Epoch[8] Validation-cross-entropy=0.000366\n",
      "2019-06-04 16:12:18,660 [INFO]  Epoch[8] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:18,932 [INFO]  Epoch[9] Batch [0-184]\tSpeed: 10990.31 samples/sec\tcross-entropy=0.006925\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:19,192 [INFO]  Epoch[9] Train-cross-entropy=0.012340\n",
      "2019-06-04 16:12:19,194 [INFO]  Epoch[9] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:19,196 [INFO]  Epoch[9] Time cost=0.534\n",
      "2019-06-04 16:12:19,205 [INFO]  Saved checkpoint to \"imputer_model/model-0009.params\"\n",
      "2019-06-04 16:12:19,244 [INFO]  Epoch[9] Validation-cross-entropy=0.002657\n",
      "2019-06-04 16:12:19,246 [INFO]  Epoch[9] Validation-3-accuracy=0.000000\n",
      "2019-06-04 16:12:19,547 [INFO]  Epoch[10] Batch [0-184]\tSpeed: 9965.40 samples/sec\tcross-entropy=0.005685\t3-accuracy=0.000000\n",
      "2019-06-04 16:12:19,790 [INFO]  Epoch[10] Train-cross-entropy=0.003032\n",
      "2019-06-04 16:12:19,792 [INFO]  Epoch[10] Train-3-accuracy=0.000000\n",
      "2019-06-04 16:12:19,793 [INFO]  Epoch[10] Time cost=0.545\n",
      "2019-06-04 16:12:19,800 [INFO]  Saved checkpoint to \"imputer_model/model-0010.params\"\n",
      "2019-06-04 16:12:19,824 [INFO]  No improvement detected for 5 epochs compared to 0.00013178860234159113 last error obtained: 0.0002905159365959329, stopping here\n",
      "2019-06-04 16:12:19,826 [INFO]  \n",
      "========== done (5.906533241271973 s) fit model\n"
     ]
    }
   ],
   "source": [
    "# Waehle eine beliebige FD, auf der datawig regressiert\n",
    "rhs = list(fds.keys())[0]\n",
    "lhs = fds[rhs][0]\n",
    "relevant_cols = lhs + [rhs]\n",
    "\n",
    "# ml_imputer() ist ein wrapper fuer datawig.SimpleImputer()\n",
    "df_imputed = fd_imputer.ml_imputer(df_train.iloc[:,relevant_cols], df_test.iloc[:,relevant_cols], rhs)\n",
    "\n",
    "y_pred = df_imputed.loc[:, str(rhs)+'_imputed']\n",
    "y_true = df_imputed.loc[:, str(rhs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-5f584f3c513d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m {\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m }\n",
      "\u001b[0;32m~/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1567\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1570\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                          str(average_options))\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "{\n",
    "'precision': metrics.precision_score(y_true, y_pred, average='weighted'),\n",
    "'recall': metrics.recall_score(y_true, y_pred, average='weighted'),\n",
    "'f1': metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Problem lie√üe sich umgehen, indem Werte aus y_pred gerundet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/philipp/code/python-envs/mlfd/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0011578136578136579"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_true, y_pred.apply(lambda x: round(x)), average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aber das ist glaube ich nicht wirklich sinnvoll - bei Regression geht es ja nicht darum, einen exakten Wert auszugeben, sondern vielmehr darum, den mittleren Fehler der einzelnen Vorhersagen zu minimieren.\n",
    "So w√ºrde ein gutes Modell, dessen Vorhersagen aber immer um ¬±0.5 neben dem korrekten Wert liegen, einen f1-Score von 0 haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ k√∂nnte man relative oder absolute Fehler berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0.0663%\n"
     ]
    }
   ],
   "source": [
    "average_rel_error = abs((y_true.mean() - y_pred.mean()) / y_true.mean())\n",
    "print(\"{:10.4f}\".format(100*average_rel_error)+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
