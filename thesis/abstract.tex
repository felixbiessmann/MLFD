\begin{abstract}
In this thesis the applicability of empirical risk minimization techniques for approximate functional dependency detection is explored.
A measure called `robustness' is introduced to assess the ability of a functional dependency when used for value imputation.
Robustness is measured for functional dependencies from a selection of datasets and functional dependencies are ranked by robustness.
Imputations derived from functional dependencies are compared to imputations derived from a model trained using the DataWig framework.
It is shown that trained imputation models share some properties with two relaxed functional dependencies.
Finally, an algorithm for relaxed functional dependency detection based on learned imputation models is presented.
\end{abstract}
